{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim\n",
    "#import torchvision.utils as vutils\n",
    "import core.DispNetS as DispNetS\n",
    "import core.FlowNet as FlowNet\n",
    "import core.PoseNet as PoseNet\n",
    "from core.sequence_folders import SequenceFolder\n",
    "from core.sequence_folders import testSequenceFolder\n",
    "import time\n",
    "import os\n",
    "import yaml\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.misc import imresize\n",
    "import torchvision.transforms as transforms\n",
    "# from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def scale_pyramid(img, num_scales):\n",
    "    # img: (b, ch, h, w)\n",
    "    if img is None:\n",
    "        return None\n",
    "    else:\n",
    "\n",
    "        # TODO: Shape of image is [channels, h, w]     \n",
    "        b, ch, h, w = img.shape\n",
    "        scaled_imgs = [img.permute(0,2,3,1)]\n",
    "#         print(scaled_imgs[0])\n",
    "        \n",
    "        for i in range(num_scales - 1):\n",
    "            ratio = 2 ** (i+1)\n",
    "            nh = int(h/ratio)\n",
    "            nw = int(w/ratio)\n",
    "            \n",
    "            scaled_img = torch.nn.functional.interpolate(img, size=(nh, nw), mode='area')\n",
    "            scaled_img = scaled_img.permute(0, 2, 3, 1)\n",
    "            \n",
    "            scaled_imgs.append(scaled_img)        \n",
    "\n",
    "        # scaled_imgs: (scales, b, h, w, ch)\n",
    "        \n",
    "    return scaled_imgs\n",
    "\n",
    "\n",
    "def L2_norm(x, dim, keep_dims=True):\n",
    "    curr_offset = 1e-10\n",
    "    l2_norm = torch.norm(torch.abs(x) + curr_offset,\n",
    "                         dim=dim, keepdim=keep_dims)\n",
    "    return l2_norm\n",
    "\n",
    "\n",
    "def DSSIM(x, y):\n",
    "    \n",
    "    avepooling2d = torch.nn.AvgPool2d(3, stride=1, padding=[1, 1])\n",
    "    x = x.permute(0, 3, 1, 2)\n",
    "    y = y.permute(0, 3, 1, 2)\n",
    "    mu_x = avepooling2d(x)\n",
    "    mu_y = avepooling2d(y)\n",
    "\n",
    "    sigma_x = avepooling2d(x**2) - mu_x**2\n",
    "    sigma_y = avepooling2d(y**2) - mu_y**2\n",
    "    sigma_xy = avepooling2d(x*y) - mu_x*mu_y\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "    # L_square = 255**2\n",
    "\n",
    "    SSIM_n = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)\n",
    "    SSIM_d = (mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2)\n",
    "\n",
    "    SSIM = SSIM_n/SSIM_d\n",
    "\n",
    "    return torch.clamp((1 - SSIM.permute(0, 2,3,1))/2, 0, 1)\n",
    "\n",
    "\n",
    "def gradient_x(img):    #checks out\n",
    "    return img[:, :, :-1, :] - img[:, :, 1:, :]\n",
    "\n",
    "def gradient_y(img):    #checks out\n",
    "    return img[:, :-1, :, :] - img[:, 1:, :, :]\n",
    "\n",
    "def compute_multi_scale_intrinsics(intrinsics, num_scales):\n",
    "\n",
    "    batch_size = intrinsics.shape[0]\n",
    "    multi_scale_intrinsices = []\n",
    "    for s in range(num_scales):\n",
    "        fx = intrinsics[:, 0, 0]/(2**s)\n",
    "        fy = intrinsics[:, 1, 1]/(2**s)\n",
    "        cx = intrinsics[:, 0, 2]/(2**s)\n",
    "        cy = intrinsics[:, 1, 2]/(2**s)\n",
    "        zeros = torch.zeros(batch_size).float().to(device)\n",
    "        r1 = torch.stack([fx, zeros, cx], dim=1)  # shape: batch_size,3\n",
    "        r2 = torch.stack([zeros, fy, cy], dim=1)  # shape: batch_size,3\n",
    "        # shape: batch_size,3\n",
    "        r3 = torch.tensor([0., 0., 1.]).float().view(\n",
    "            1, 3).repeat(batch_size, 1).to(device)\n",
    "        # concat along the spatial row dimension\n",
    "        scale_instrinsics = torch.stack([r1, r2, r3], dim=1)\n",
    "        multi_scale_intrinsices.append(\n",
    "            scale_instrinsics)  # shape: num_scale,bs,3,3\n",
    "    multi_scale_intrinsices = torch.stack(multi_scale_intrinsices, dim=1)\n",
    "    return multi_scale_intrinsices\n",
    "\n",
    "def euler2mat(z, y, x):\n",
    "    global device\n",
    "    # TODO: eular2mat\n",
    "    '''\n",
    "    input shapes of z,y,x all are: (#batch)\n",
    "    '''\n",
    "    batch_size = z.shape[0]\n",
    "\n",
    "    _z = z.clamp(-np.pi, np.pi)\n",
    "    _y = y.clamp(-np.pi, np.pi)\n",
    "    _x = x.clamp(-np.pi, np.pi)\n",
    "\n",
    "    ones = torch.ones(batch_size).float().to(device)\n",
    "    zeros = torch.zeros(batch_size).float().to(device)\n",
    "\n",
    "    cosz = torch.cos(z)\n",
    "    sinz = torch.sin(z)\n",
    "    # shape: (#batch,3)\n",
    "    rotz_mat_r1 = torch.stack((cosz, -sinz, zeros), dim=1)\n",
    "    rotz_mat_r2 = torch.stack((sinz, cosz, zeros), dim=1)\n",
    "    rotz_mat_r3 = torch.stack((zeros, zeros, ones), dim=1)\n",
    "    # shape: (#batch,3,3)\n",
    "    rotz_mat = torch.stack((rotz_mat_r1, rotz_mat_r2, rotz_mat_r3), dim=1)\n",
    "\n",
    "    cosy = torch.cos(y)\n",
    "    siny = torch.sin(y)\n",
    "    roty_mat_r1 = torch.stack((cosy, zeros, siny), dim=1)\n",
    "    roty_mat_r2 = torch.stack((zeros, ones, zeros), dim=1)\n",
    "    roty_mat_r3 = torch.stack((-siny, zeros, cosy), dim=1)\n",
    "    roty_mat = torch.stack((roty_mat_r1, roty_mat_r2, roty_mat_r3), dim=1)\n",
    "\n",
    "    cosx = torch.cos(x)\n",
    "    sinx = torch.sin(x)\n",
    "    rotx_mat_r1 = torch.stack((ones, zeros, zeros), dim=1)\n",
    "    rotx_mat_r2 = torch.stack((zeros, cosx, -sinx), dim=1)\n",
    "    rotx_mat_r3 = torch.stack((zeros, sinx, cosx), dim=1)\n",
    "    rotx_mat = torch.stack((rotx_mat_r1, rotx_mat_r2, rotx_mat_r3), dim=1)\n",
    "\n",
    "    # shape: (#batch,3,3)\n",
    "    rot_mat = torch.matmul(torch.matmul(rotx_mat, roty_mat), rotz_mat)\n",
    "    \n",
    "#     rot_mat = torch.matmul(rotz_mat, torch.matmul(roty_mat, rotx_mat))\n",
    "\n",
    "    return rot_mat\n",
    "\n",
    "def pixel2cam(depth, pixel_coords, intrinsics, is_homogeneous=True):\n",
    "    global device\n",
    "    \n",
    "    \"\"\"Transform coordinates in the pixel frame to the camera frame.\n",
    "    Args:\n",
    "        depth: depth maps -- [B, H, W]\n",
    "        intrinsics_inv: intrinsics_inv matrix for each element of batch -- [B, 3, 3]\n",
    "    Returns:\n",
    "        array of (u,v,1) cam coordinates -- [B, 3, H, W]\n",
    "    \"\"\"\n",
    "    \n",
    "    b, h, w = depth.size()\n",
    "    \n",
    "    depth = depth.view(b, 1, -1)\n",
    "    pixel_coords = pixel_coords.view(b, 3, -1)\n",
    "    cam_coords = torch.matmul(torch.inverse(intrinsics), pixel_coords) * depth\n",
    "    \n",
    "    if is_homogeneous:\n",
    "        ones = torch.ones(b, 1, h*w).float().to(device)\n",
    "        cam_coords = torch.cat((cam_coords.to(device), ones), dim=1)\n",
    "    \n",
    "    cam_coords = cam_coords.view(b, -1, h, w)\n",
    "    \n",
    "    return cam_coords\n",
    "\n",
    "def cam2pixel(cam_coords, proj):\n",
    "    global device\n",
    "    \n",
    "    \"\"\"Transforms coordinates in a camera frame to the pixel frame.\n",
    "\n",
    "    Args:\n",
    "    cam_coords: [batch, 4, height, width]\n",
    "    proj: [batch, 4, 4]\n",
    "    Returns:\n",
    "    Pixel coordinates projected from the camera frame [batch, height, width, 2]\n",
    "    \"\"\"\n",
    "    b, _, h, w = cam_coords.size()\n",
    "    cam_coords = cam_coords.view(b, 4, h*w)\n",
    "    unnormalized_pixel_coords = torch.matmul(proj, cam_coords)\n",
    "    \n",
    "    x_u = unnormalized_pixel_coords[:, :1, :]\n",
    "    y_u = unnormalized_pixel_coords[:, 1:2, :]\n",
    "    z_u = unnormalized_pixel_coords[:, 2:3, :]\n",
    "    \n",
    "    x_n = x_u / (z_u + 1e-10)\n",
    "    y_n = y_u / (z_u + 1e-10)\n",
    "        \n",
    "    pixel_coords = torch.cat((x_n, y_n), dim=1)\n",
    "    pixel_coords = pixel_coords.view(b, 2, h, w)\n",
    "    \n",
    "    return pixel_coords.permute(0, 2, 3, 1)\n",
    "\n",
    "def pose_vec2mat(vec):\n",
    "    global device\n",
    "    # TODO:pose vec 2 mat\n",
    "    # input shape of vec: (#batch, 6)\n",
    "    # shape: (#batch,3)\n",
    "    \n",
    "    b, _ = vec.size()\n",
    "    translation = vec[:, :3].unsqueeze(2)\n",
    "    \n",
    "    rx = vec[:, 3]\n",
    "    ry = vec[:, 4]\n",
    "    rz = vec[:, 5]\n",
    "    \n",
    "    rot_mat = euler2mat(rz, ry, rx)\n",
    "    rot_mat = rot_mat.squeeze(1)\n",
    "    \n",
    "    filler = torch.tensor([0.,0.,0.,1.]).view(1, 4).repeat(b, 1, 1).float().to(device)\n",
    "    \n",
    "    transform_mat = torch.cat((rot_mat, translation), dim=2)\n",
    "    transform_mat = torch.cat((transform_mat, filler), dim=1)\n",
    "    \n",
    "    return transform_mat\n",
    "\n",
    "def meshgrid(batch, height, width, is_homogeneous=True):\n",
    "    \"\"\"Construct a 2D meshgrid.\n",
    "\n",
    "    Args:\n",
    "      batch: batch size\n",
    "      height: height of the grid\n",
    "      width: width of the grid\n",
    "      is_homogeneous: whether to return in homogeneous coordinates\n",
    "    \n",
    "    Returns:\n",
    "      x,y grid coordinates [batch, 2 (3 if homogeneous), height, width]\n",
    "    \"\"\"\n",
    "    \n",
    "    global device\n",
    "    \n",
    "    # (height, width)\n",
    "    x_t = torch.matmul(\n",
    "        torch.ones(height).view(height, 1).float().to(device),\n",
    "        torch.linspace(-1, 1, width).view(1, width).to(device))\n",
    "    \n",
    "    # (height, width)\n",
    "    y_t = torch.matmul(\n",
    "        torch.linspace(-1, 1, height).view(height, 1).to(device),\n",
    "        torch.ones(width).view(1, width).float().to(device))\n",
    "    \n",
    "    x_t = (x_t + 1) * 0.5 * (width-1)\n",
    "    y_t = (y_t + 1) * 0.5 * (height-1)\n",
    "        \n",
    "    if is_homogeneous:\n",
    "        ones = torch.ones_like(x_t).float().to(device)\n",
    "        #ones = torch.ones(height, width).float().to(device)\n",
    "        coords = torch.stack((x_t, y_t, ones), dim=0)  # shape: 3, h, w\n",
    "    else:\n",
    "        coords = torch.stack((x_t, y_t), dim=0)  # shape: 2, h, w\n",
    "    \n",
    "    coords = torch.unsqueeze(coords, 0).expand(batch, -1, height, width)\n",
    "\n",
    "    return coords\n",
    "\n",
    "\n",
    "def compute_rigid_flow(pose, depth, intrinsics, reverse_pose):\n",
    "    global device\n",
    "    '''Compute the rigid flow from src view to tgt view \n",
    "\n",
    "        input shapes:\n",
    "            pose: (batch, 6)\n",
    "            depth: (batch, h, w)\n",
    "            intrinsics: (batch, 3, 3)\n",
    "    '''\n",
    "    b, h, w = depth.shape\n",
    "\n",
    "    # shape: (batch, 4, 4)\n",
    "    pose = pose_vec2mat(pose) # (b, 4, 4)\n",
    "    if reverse_pose:\n",
    "        pose = torch.inverse(pose) # (b, 4, 4)\n",
    "\n",
    "    pixel_coords = meshgrid(b, h, w) # (batch, 3, h, w)\n",
    "\n",
    "    tgt_pixel_coords = pixel_coords[:,:2,:,:].permute(0, 2, 3, 1)   # (batch, h, w, 2)\n",
    "    cam_coords = pixel2cam(depth, pixel_coords, intrinsics) # (batch, 4, h, w)\n",
    "\n",
    "    # Construct 4x4 intrinsics matrix\n",
    "    filler = torch.tensor([0.,0.,0.,1.]).view(1, 4).repeat(b, 1, 1).to(device)\n",
    "    intrinsics = torch.cat((intrinsics, torch.zeros((b, 3, 1)).float().to(device)), dim=2)\n",
    "    intrinsics = torch.cat((intrinsics, filler), dim=1) # (batch, 4, 4)\n",
    "\n",
    "    proj_tgt_cam_to_src_pixel = torch.matmul(intrinsics, pose)\n",
    "    src_pixel_coords = cam2pixel(cam_coords, proj_tgt_cam_to_src_pixel)\n",
    "    \n",
    "    rigid_flow = src_pixel_coords - tgt_pixel_coords\n",
    "\n",
    "    return rigid_flow\n",
    "\n",
    "\n",
    "def flow_to_tgt_coords(src2tgt_flow):\n",
    "\n",
    "    # shape: (#batch,2,h,w)\n",
    "    batch_size, _,h,w = src2tgt_flow.shape\n",
    "    \n",
    "    # shape: (#batch,h,w,2)\n",
    "    src2tgt_flow = src2tgt_flow.clone().permute(0,2,3,1)\n",
    "\n",
    "    # shape: (#batch,h,w,2)\n",
    "    src_coords = meshgrid(h, w, False).repeat(batch_size,1,1,1)\n",
    "\n",
    "    tgt_coords = src_coords+src2tgt_flow\n",
    "\n",
    "    normalizer = torch.tensor([(2./w),(2./h)]).repeat(batch_size,h,w,1).float().to(device)\n",
    "    # shape: (#batch,h,w,2)\n",
    "    tgt_coords = tgt_coords*normalizer-1\n",
    "\n",
    "    # shape: (#batch,h,w,2)\n",
    "    return tgt_coords\n",
    "\n",
    "\n",
    "def flow_warp(src_img, flow):\n",
    "    # src_img: (8, h, w, 3) \n",
    "    # flow: (8, h, w, 2)\n",
    "\n",
    "    b, h, w, ch = src_img.size()\n",
    "    tgt_pixel_coords = meshgrid(b, h, w, False).permute(0, 2, 3, 1) # (b, h, w, ch)\n",
    "    src_pixel_coords = tgt_pixel_coords + flow\n",
    "    \n",
    "    output_img = bilinear_sampler(src_img, src_pixel_coords)\n",
    "\n",
    "    return output_img\n",
    "\n",
    "\n",
    "def bilinear_sampler(imgs, coords):\n",
    "    global device\n",
    "    \"\"\"Construct a new image by bilinear sampling from the input image.\n",
    "\n",
    "    Points falling outside the source image boundary have value 0.\n",
    "\n",
    "    Args:\n",
    "      imgs: source image to be sampled from [batch, height_s, width_s, channels]\n",
    "      coords: coordinates of source pixels to sample from [batch, height_t,\n",
    "        width_t, 2]. height_t/width_t correspond to the dimensions of the output\n",
    "        image (don't need to be the same as height_s/width_s). The two channels\n",
    "        correspond to x and y coordinates respectively.\n",
    "    Returns:\n",
    "      A new sampled image [batch, height_t, width_t, channels]\n",
    "    \"\"\"\n",
    "    # imgs: (8, 128, 416, 3)\n",
    "    # coords: (8, 128, 416, 2)\n",
    "    \n",
    "    def _repeat(x, n_repeats):\n",
    "        global device\n",
    "        rep = torch.ones(n_repeats).unsqueeze(0).float().to(device)\n",
    "        x = torch.matmul(x.view(-1, 1), rep)\n",
    "        return x.view(-1)\n",
    "    \n",
    "    coords_x = coords[:, :, :, 0].unsqueeze(3).float().to(device)\n",
    "    coords_y = coords[:, :, :, 1].unsqueeze(3).float().to(device)\n",
    "    \n",
    "    inp_size = imgs.size()\n",
    "    coord_size = coords.size()\n",
    "    out_size = torch.tensor(coords.size())\n",
    "    out_size[3] = imgs.size()[3]\n",
    "    out_size = list(out_size)\n",
    "    \n",
    "    x0 = torch.floor(coords_x)\n",
    "    x1 = x0 + 1\n",
    "    y0 = torch.floor(coords_y)\n",
    "    y1 = y0 + 1\n",
    "    \n",
    "    y_max = torch.tensor(imgs.size()[1] - 1).float()\n",
    "    x_max = torch.tensor(imgs.size()[2] - 1).float()\n",
    "    zero = torch.zeros([]).float()\n",
    "    \n",
    "    x0_safe = torch.clamp(x0, zero, x_max)\n",
    "    y0_safe = torch.clamp(y0, zero, y_max)\n",
    "    x1_safe = torch.clamp(x1, zero, x_max)\n",
    "    y1_safe = torch.clamp(y1, zero, y_max)\n",
    "    \n",
    "    wt_x0 = x1_safe - coords_x\n",
    "    wt_x1 = coords_x - x0_safe\n",
    "    wt_y0 = y1_safe - coords_y\n",
    "    wt_y1 = coords_y - y0_safe\n",
    "    \n",
    "    dim2 = torch.tensor(inp_size[2]).float().to(device)\n",
    "    dim1 = torch.tensor(inp_size[2] * inp_size[1]).float().to(device)\n",
    "    \n",
    "    base_in = _repeat(torch.from_numpy(np.arange(coord_size[0])).float().to(device) * dim1, \n",
    "                      coord_size[1]*coord_size[2])\n",
    "    \n",
    "    base = torch.reshape(base_in, (coord_size[0], coord_size[1], coord_size[2], 1))\n",
    "    \n",
    "    base_y0 = base + y0_safe*dim2\n",
    "    base_y1 = base + y1_safe*dim2\n",
    "    \n",
    "    idx00 = torch.reshape(x0_safe + base_y0, (-1,)).to(torch.int32).long()\n",
    "    idx01 = torch.reshape(x0_safe + base_y1, (-1,)).to(torch.int32).long()\n",
    "    idx10 = torch.reshape(x1_safe + base_y0, (-1,)).to(torch.int32).long()\n",
    "    idx11 = torch.reshape(x1_safe + base_y1, (-1,)).to(torch.int32).long()\n",
    "\n",
    "#     imgs_flat = torch.reshape(imgs, (-1, inp_size[3])).float()\n",
    "    imgs_flat = imgs.contiguous().view(-1, inp_size[3]).float()\n",
    "\n",
    "    im00 = torch.index_select(imgs_flat, 0, idx00).view(out_size)\n",
    "    im01 = torch.index_select(imgs_flat, 0, idx01).view(out_size)\n",
    "    im10 = torch.index_select(imgs_flat, 0, idx10).view(out_size)\n",
    "    im11 = torch.index_select(imgs_flat, 0, idx11).view(out_size)\n",
    "    \n",
    "    \n",
    "    w00 = wt_x0 * wt_y0\n",
    "    w01 = wt_x0 * wt_y1\n",
    "    w10 = wt_x1 * wt_y0\n",
    "    w11 = wt_x1 * wt_y1\n",
    "\n",
    "    output = (w00*im00) + (w01*im01) + (w10*im10) + (w11*im11)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_similarity(alpha,x,y):\n",
    "    # print('alpha*DSSIM(x,y): {:.16f}\\n torch.abs(x-y): {:.16f}'.format(torch.mean(alpha*DSSIM(x,y)),torch.mean((1-alpha)*torch.abs(x-y))))\n",
    "    return alpha * DSSIM(x,y) + (1-alpha) * torch.abs(x - y)\n",
    "\n",
    "def smooth_loss(depth,image):\n",
    "    # depth: (12, h, w, 1)\n",
    "    # image: (12, h, w, 3)\n",
    "    \n",
    "    gradient_depth_x = gradient_x(depth)  # (TODO)shape: bs,h,w,1\n",
    "    gradient_depth_y = gradient_y(depth)\n",
    "\n",
    "    gradient_img_x = gradient_x(image)  # (TODO)shape: bs,h,w,3\n",
    "    gradient_img_y = gradient_y(image)\n",
    "\n",
    "    exp_gradient_img_x = torch.exp(-torch.mean(torch.abs(gradient_img_x), 3, True)) # (TODO)shape: bs,h,w,1\n",
    "    exp_gradient_img_y = torch.exp(-torch.mean(torch.abs(gradient_img_y), 3, True)) \n",
    "\n",
    "    smooth_x = gradient_depth_x*exp_gradient_img_x\n",
    "    smooth_y = gradient_depth_y*exp_gradient_img_y\n",
    "\n",
    "    return torch.mean(torch.abs(smooth_x))+torch.mean(torch.abs(smooth_y))\n",
    "\n",
    "def flow_smooth_loss(flow,img):\n",
    "    # TODO two flows ?= rigid flow + object motion flow\n",
    "    smoothness = 0\n",
    "    for i in range(2):\n",
    "        # TODO shape of flow: bs,channels(2),h,w\n",
    "        smoothness += smooth_loss(flow[:, i, :, :].unsqueeze(1), img)\n",
    "    return smoothness/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "global n_iter\n",
    "n_iter = 0\n",
    "\n",
    "class GeoNetModel(object):\n",
    "    def __init__(self, config, train_flow, device):\n",
    "        self.config = config\n",
    "        \n",
    "        self.num_source = self.config['sequence_length'] - 1\n",
    "        self.batch_size = self.config['batch_size']\n",
    "        self.num_scales = torch.tensor(config['num_scales'])\n",
    "        self.simi_alpha = torch.tensor(\n",
    "            config['alpha_recon_image']).float().to(device)\n",
    "        self.geometric_consistency_alpha = torch.tensor(\n",
    "            config['geometric_consistency_alpha']).float().to(device)\n",
    "        self.geometric_consistency_beta = torch.tensor(\n",
    "            config['geometric_consistency_beta']).float().to(device)\n",
    "        self.loss_weight_rigid_warp = torch.tensor(     # 1.0\n",
    "            config['lambda_rw']).float().to(device)\n",
    "        self.loss_weight_disparity_smooth = torch.tensor(   # 0.5\n",
    "            config['lambda_ds']).float().to(device)\n",
    "        self.loss_weight_full_warp = torch.tensor(\n",
    "            config['lambda_fw']).float().to(device)\n",
    "        self.loss_weigtht_full_smooth = torch.tensor(\n",
    "            config['lambda_fs']).float().to(device)\n",
    "        self.loss_weight_geometrical_consistency = torch.tensor(\n",
    "            config['lambda_gc']).float().to(device)\n",
    "        \n",
    "        self.epochs = self.config['epochs']\n",
    "        self.epoch_size = self.config['epoch_size']\n",
    "        self.output_ckpt_iter = self.config['save_ckpt_iter']\n",
    "        self.train_flow = train_flow\n",
    "        self.is_train = self.config['is_train']\n",
    "        \n",
    "        # Nets preparation\n",
    "        #self.disp_net = DispNet.DispNet()\n",
    "        self.disp_net = DispNetS.DispNetS()\n",
    "        self.pose_net = PoseNet.PoseNet(self.num_source)\n",
    "        \n",
    "        \n",
    "        # input channels: src_views * (3 tgt_rgb + 3 src_rgb + 3 warp_rgb + 2 flow_xy +1 error )\n",
    "        self.flow_net = FlowNet.FlowNet(12, self.config['flow_scale_factor'])\n",
    "\n",
    "        if device.type == 'cuda':\n",
    "            self.disp_net.cuda()\n",
    "            self.pose_net.cuda()\n",
    "            self.flow_net.cuda()\n",
    "\n",
    "        #Weight initialization\n",
    "        if (not self.train_flow) and not config['save_from_ckpt']:\n",
    "            print('Initializing weights from scratch')\n",
    "            self.disp_net.init_weight()\n",
    "            self.pose_net.init_weight()\n",
    "\n",
    "        if config['save_from_ckpt']:\n",
    "            path = '{}/{}_{}'.format(config['ckpt_dir'], 'rigid_', str(config['ckpt_index']) + '.pth')\n",
    "            print('Loading saved model weights from {}'.format(path))\n",
    "            ckpt = torch.load(path)\n",
    "            self.disp_net.load_state_dict(ckpt['disp_net_state_dict'])\n",
    "            self.pose_net.load_state_dict(ckpt['pose_net_state_dict'])\n",
    "\n",
    "        \"\"\"\n",
    "        else:\n",
    "            ckpt = torch.load(config['ckpt_path'])\n",
    "            self.disp_net.load_state_dict(ckpt['disp_net_state_dict'])\n",
    "            self.pose_net.load_state_dict(ckpt['pose_net_state_dict'])\n",
    "            if train_flow:\n",
    "                if 'flow_net_state_dict' in ckpt:\n",
    "                    self.flow_net.load_state_dict(ckpt['flow_net_state_dict'])\n",
    "                else:\n",
    "                    self.flow_net.init_weight()\n",
    "        \"\"\"\n",
    "\n",
    "        # for multiple GPUs\n",
    "        # TODO: load pretrained weights saved with DataParallel\n",
    "        # self.disp_net = torch.nn.DataParallel(self.disp_net)\n",
    "        # self.pose_net = torch.nn.DataParallel(self.pose_net)\n",
    "\n",
    "        self.nets = {\n",
    "            'disp': self.disp_net,\n",
    "            'pose': self.pose_net,\n",
    "            'flow': self.flow_net\n",
    "        }\n",
    "\n",
    "        self.graphs_dir = config['graphs_dir']\n",
    "#         self.tensorboard_writer = SummaryWriter(logdir=self.graphs_dir, flush_secs=30)\n",
    "\n",
    "        print('Writing graphs to {}'.format(self.graphs_dir))\n",
    "\n",
    "    def preprocess_test_data(self, sampled_batch):\n",
    "        \"\"\"\n",
    "        sampled_batch: (batch_size, img_height, img_width, channels)\n",
    "        \"\"\"\n",
    "\n",
    "        tgt_view = sampled_batch\n",
    "        tgt_view = tgt_view.to(device).float()\n",
    "        tgt_view *= 1./255.\n",
    "        self.tgt_view = tgt_view*2.0 - 1.0\n",
    "\n",
    "        #shape:  #scale, #batch, #chnls, h,w\n",
    "        self.tgt_view_pyramid = scale_pyramid(self.tgt_view, self.num_scales)\n",
    "        #shape:  #scale, #batch*#src_views, #chnls,h,w\n",
    "        self.tgt_view_tile_pyramid = [\n",
    "            self.tgt_view_pyramid[scale].repeat(self.num_source, 1, 1, 1)\n",
    "            for scale in range(self.num_scales)\n",
    "        ]\n",
    "\n",
    "        self.src_views = None\n",
    "        self.intrinsics = None\n",
    "        self.src_views_concat = None\n",
    "        self.src_views_pyramid = None\n",
    "        self.multi_scale_intrinsices = None\n",
    " \n",
    "    def iter_data_preparation(self, sampled_batch):\n",
    "        # sampled_batch: tgt_view, src_views, intrinsics\n",
    "        # shape: batch,chnls h,w\n",
    "        tgt_view = sampled_batch[0]\n",
    "        # shape: batch,num_source,chnls,h,w\n",
    "        src_views = sampled_batch[1]\n",
    "        # shape: batch,3,3\n",
    "        intrinsics = sampled_batch[2]\n",
    "        # The images here are integral (0-255)\n",
    "        \n",
    "#         tgt_view = torch.tensor(np.load('/ceph/raunaks/tgt.npy')).permute(0, 3, 1, 2)#integers, b,c,h,w after permute\n",
    "#         src_views = torch.tensor(np.load('/ceph/raunaks/src.npy')).permute(0, 3, 1, 2)\n",
    "        \n",
    "#         plt.imshow(tgt_view[0].permute(1,2,0))\n",
    "        \n",
    "        # to device\n",
    "        # shape: #batch,3,h,w\n",
    "        self.tgt_view = tgt_view.to(device).float()\n",
    "        self.tgt_view *= 1./255.\n",
    "        self.tgt_view = self.tgt_view*2. - 1.\n",
    "        \n",
    "#         print(self.tgt_view.permute(0,2,3,1))\n",
    "#         plt.imshow((self.tgt_view[0].permute(1,2,0)+1)/2.)\n",
    "        \n",
    "        self.src_views = src_views.to(device).float()\n",
    "        self.src_views *= 1./255.\n",
    "        self.src_views = self.src_views*2. - 1.\n",
    "        #print(self.src_views, self.tgt_view)\n",
    "        \n",
    "        self.intrinsics = intrinsics.to(device).float()\n",
    "        # shape: b*src_views,6,h,w\n",
    "        self.src_views_concat = torch.cat([\n",
    "            self.src_views[:, 3*s:3*(s + 1), :, :]\n",
    "            for s in range(self.num_source)\n",
    "        ], dim=0)\n",
    "        \n",
    "\n",
    "        #shape:  #scale, #batch, h,w, ch\n",
    "        self.tgt_view_pyramid = scale_pyramid(self.tgt_view, self.num_scales)\n",
    "        \n",
    "#         print(self.tgt_view_pyramid[0][0].shape, self.tgt_view_pyramid[0][0])\n",
    "        \n",
    "        #shape:  #scale, #batch*#src_views, #chnls,h,w\n",
    "        self.tgt_view_tile_pyramid = [\n",
    "            self.tgt_view_pyramid[scale].repeat(self.num_source, 1, 1, 1)\n",
    "            for scale in range(self.num_scales)\n",
    "        ]\n",
    "        \n",
    "#         print(self.tgt_view_tile_pyramid[0].shape, self.tgt_view_tile_pyramid[1][0])\n",
    "#         plt.imshow((self.tgt_view_tile_pyramid[1][0]+1)/2.)\n",
    "\n",
    "        #shape: scales, b*src_views, h, w, ch\n",
    "        self.src_views_pyramid = scale_pyramid(self.src_views_concat,\n",
    "                                               self.num_scales)\n",
    "\n",
    "        # output multiple disparity prediction\n",
    "        self.multi_scale_intrinsices = compute_multi_scale_intrinsics(\n",
    "            self.intrinsics, self.num_scales)\n",
    "        \n",
    "#         self.multi_scale_intrinsices = torch.tensor(np.load('/ceph/raunaks/intrin.npy'))\n",
    "        \n",
    "    def spatial_normalize(self, disp):\n",
    "        curr_c, _, curr_h, curr_w = list(disp.size())\n",
    "        disp_mean = torch.mean(disp, dim=(0, 2, 3), keepdim=True)\n",
    "        disp_exp = disp_mean.expand(disp.size())\n",
    "        return disp/disp_exp\n",
    "        \n",
    "    def build_dispnet(self):\n",
    "        # shape: batch, channels, height, width\n",
    "        self.dispnet_inputs = self.tgt_view\n",
    "        \n",
    "        # for multiple disparity predictions,\n",
    "        # cat tgt_view and src_views along the batch dimension\n",
    "        if self.is_train:\n",
    "            for s in range(self.num_source):    #opt.num_source = 3 - 1 = 2\n",
    "                self.dispnet_inputs = torch.cat((self.dispnet_inputs, self.src_views[:, 3*s : 3*(s + 1), :, :]), dim=0)\n",
    "            # [12, 3, 128, 416] - bs*3, channels, height, width\n",
    "\n",
    "        # shape: pyramid_scales, #batch+#batch*#src_views, h,w\n",
    "        self.disparities = self.disp_net(self.dispnet_inputs)\n",
    "        self.loss_disparities = [d.squeeze(1).unsqueeze(3) for d in self.disparities]\n",
    "        print(self.loss_disparities[0].size(), torch.mean(self.loss_disparities[0]), self.loss_disparities)\n",
    "        \"\"\"\n",
    "        Length = 4\n",
    "        disparities[0]: (12, 1, 128, 416)\n",
    "        disparities[1]: (12, 1, 64, 208)\n",
    "        disparities[2]: (12, 1, 32, 104)\n",
    "        disparities[3]: (12, 1, 16, 52)\n",
    "        \"\"\"\n",
    "        # shape: pyramid_scales, bs, h,w\n",
    "        \n",
    "        #self.depth = [self.spatial_normalize(disp) for disp in self.disparities]\n",
    "        \n",
    "        self.depth = [1.0/disp for disp in self.disparities]\n",
    "        \n",
    "        self.depth = [d.squeeze_(1) for d in self.depth]    #is this even necessary? Yes, in the tf implementation it is done inside the compute_rigid_flow function\n",
    "#         print(self.depth)\n",
    "        \"\"\"\n",
    "        For training data:\n",
    "        Length = 4\n",
    "        depth[0]: (12, 128, 416)\n",
    "        depth[1]: (12, 64, 208)\n",
    "        depth[2]: (12, 32, 104)\n",
    "        depth[3]: (12, 16, 52)\n",
    "        i.e. (batch_size*num_imgs, height, width)\n",
    "        \"\"\"\n",
    "\n",
    "    def build_posenet(self):\n",
    "        self.posenet_inputs = torch.cat((self.tgt_view, self.src_views), dim=1)        \n",
    "#         print(self.posenet_inputs.permute(0, 2, 3, 1).size(), \n",
    "#               self.posenet_inputs.permute(0, 2, 3, 1))\n",
    "        self.poses = self.pose_net(self.posenet_inputs)\n",
    "#         print(self.poses.shape, self.poses)\n",
    "        # (batch_size, num_source, 6)\n",
    "    \n",
    "    def build_rigid_warp_flow(self):\n",
    "        global n_iter\n",
    "        # NOTE: this should be a python list,\n",
    "        # since the sizes of different level of the pyramid are not same\n",
    "        \"\"\"\n",
    "        Uses self.poses and self.depth, computed through build_posenet() and build_dispnet(), respectively\n",
    "        \"\"\"\n",
    "        import pickle\n",
    "        \n",
    "#         infile = open('/ceph/raunaks/depth2.pkl', 'rb')\n",
    "#         self.depth = pickle.load(infile)\n",
    "#         self.depth = [torch.tensor(d).squeeze(3) for d in self.depth]\n",
    "#         print(self.depth[0].size())\n",
    "        \n",
    "#         infile = open('/ceph/raunaks/pose2.pkl', 'rb')\n",
    "#         self.poses = pickle.load(infile)\n",
    "#         self.poses = torch.tensor(self.poses)\n",
    "#         print(self.poses.shape)\n",
    "        \n",
    "#         infile = open('/ceph/raunaks/intrin2.pkl', 'rb')\n",
    "#         self.multi_scale_intrinsices = torch.tensor(pickle.load(infile))\n",
    "#         print(self.multi_scale_intrinsices.shape)\n",
    "        \n",
    "        self.fwd_rigid_flow_pyramid = []\n",
    "        self.bwd_rigid_flow_pyramid = []\n",
    "\n",
    "        for scale in range(self.num_scales):    #num_scales is 4\n",
    "\n",
    "            for src in range(self.num_source):  #num_source is 2\n",
    "                # self.depth: (4, 12, _, _)\n",
    "                # self.poses: (4, 2, 6)\n",
    "                # self.multi_scale_intrinsices: (4, 4, 3, 3)\n",
    "                                \n",
    "                # (4, h, w, 2) for each particular scale\n",
    "                fwd_rigid_flow = compute_rigid_flow( # Checks out\n",
    "                    self.poses[:, src, :],\n",
    "                    self.depth[scale][:self.batch_size, :, :],\n",
    "                    self.multi_scale_intrinsices[:, scale, :, :], False)\n",
    "                \n",
    "#                 print(\"flow-src-px\", tmp0.size(), tmp0)\n",
    "\n",
    "                # (4, h, w, 2)\n",
    "                bwd_rigid_flow = compute_rigid_flow(\n",
    "                    self.poses[:, src, :],\n",
    "                    self.depth[scale][self.batch_size * (\n",
    "                        src + 1):self.batch_size * (src + 2), :, :],\n",
    "                    self.multi_scale_intrinsices[:, scale, :, :], True)\n",
    "                \n",
    "                if not src:\n",
    "                    fwd_rigid_flow_cat = fwd_rigid_flow\n",
    "                    bwd_rigid_flow_cat = bwd_rigid_flow\n",
    "                else:\n",
    "                    fwd_rigid_flow_cat = torch.cat(\n",
    "                        (fwd_rigid_flow_cat, fwd_rigid_flow), dim=0)\n",
    "                    bwd_rigid_flow_cat = torch.cat(\n",
    "                        (bwd_rigid_flow_cat, bwd_rigid_flow), dim=0)\n",
    "            \n",
    "            # After the inner loop runs: fwd_rigid_flow_cat - (b*src_imgs, h, w, 2)\n",
    "            \n",
    "            self.fwd_rigid_flow_pyramid.append(fwd_rigid_flow_cat)\n",
    "            self.bwd_rigid_flow_pyramid.append(bwd_rigid_flow_cat)\n",
    "\n",
    "        #After the outer loop runs: fwd_rigid_flow_pyramid: (scales, b*src_imgs, h, w, 2) like (4, 8, h, w, 2)\n",
    "        \n",
    "        self.fwd_rigid_warp_pyramid = [\n",
    "            flow_warp(self.src_views_pyramid[scale],\n",
    "                      self.fwd_rigid_flow_pyramid[scale])\n",
    "            for scale in range(self.num_scales)\n",
    "        ]\n",
    "                \n",
    "#         print(self.fwd_rigid_warp_pyramid[0].shape, self.fwd_rigid_warp_pyramid) - different\n",
    "#         print(self.tmp_pyramid[0].shape, self.tmp_pyramid)\n",
    "        \n",
    "        self.bwd_rigid_warp_pyramid = [\n",
    "            flow_warp(self.tgt_view_tile_pyramid[scale],\n",
    "                      self.bwd_rigid_flow_pyramid[scale])\n",
    "            for scale in range(self.num_scales)\n",
    "        ]\n",
    "\n",
    "        #print(len(self.fwd_rigid_warp_pyramid), \" \", self.fwd_rigid_warp_pyramid[0].size())\n",
    "        #fwd_rigid_warp_pyramid: (8,128,416,3), (8,64,208,3), (8,32,104,3), (8,16,52,3)\n",
    "        \n",
    "#         if n_iter % 1000 == 0:\n",
    "#             for j in range(len(self.fwd_rigid_warp_pyramid)):\n",
    "#                 x = self.fwd_rigid_warp_pyramid[j].permute(0, 3, 1, 2)\n",
    "#                 x = (x - torch.min(x))/(torch.max(x)-torch.min(x))\n",
    "#                 self.tensorboard_writer.add_images('fwd_rigid_warp_scale' + str(j), x, n_iter)\n",
    " \n",
    "#             for j in range(len(self.bwd_rigid_warp_pyramid)):\n",
    "#                 x = self.fwd_rigid_warp_pyramid[j].permute(0, 3, 1, 2)\n",
    "#                 x = (x - torch.min(x))/(torch.max(x)-torch.min(x))\n",
    "#                 self.tensorboard_writer.add_images('bwd_rigid_warp_scale' + str(j), x, n_iter)\n",
    "\n",
    "#         print(torch.mean(self.bwd_rigid_warp_pyramid[0]))\n",
    "#         print(\"fwdpyr\", self.fwd_rigid_warp_pyramid[0])\n",
    "#         print(\"bwdpyr\", self.bwd_rigid_warp_pyramid[0])\n",
    "\n",
    "#         a = self.fwd_rigid_warp_pyramid[0]\n",
    "    \n",
    "        self.fwd_rigid_error_pyramid = [\n",
    "            image_similarity(self.simi_alpha,\n",
    "                             self.tgt_view_tile_pyramid[scale],\n",
    "                             self.fwd_rigid_warp_pyramid[scale])\n",
    "            for scale in range(self.num_scales)\n",
    "        ]\n",
    "        self.bwd_rigid_error_pyramid = [\n",
    "            image_similarity(self.simi_alpha, self.src_views_pyramid[scale],\n",
    "                             self.bwd_rigid_warp_pyramid[scale])\n",
    "            for scale in range(self.num_scales)\n",
    "        ]\n",
    "#         print(self.fwd_rigid_error_pyramid[0])\n",
    "\n",
    "        \n",
    "#         if n_iter % 1000 == 0:\n",
    "#             self.fwd_rigid_error_scale=[]\n",
    "#             self.bwd_rigid_error_scale=[]\n",
    "#             #fwd_rigid_error_pyramid[0]: (8, 3, 128, 416)\n",
    "\n",
    "#             for j in range(len(self.fwd_rigid_error_pyramid)):\n",
    "#                 tmp=torch.mean(self.fwd_rigid_error_pyramid[j].permute(0, 3, 1, 2), dim=1, keepdim=True)\n",
    "#                 #tmp: (8, 1, 128, 416) in 1st iteration\n",
    "#                 self.tensorboard_writer.add_images('fwd_rigid_error_scale' + str(j), tmp, n_iter)\n",
    "#                 self.fwd_rigid_error_scale.append(tmp)\n",
    "\n",
    "#             for j in range(len(self.bwd_rigid_error_pyramid)):\n",
    "#                 tmp=torch.mean(self.bwd_rigid_error_pyramid[j].permute(0, 3, 1, 2), dim=1, keepdim=True)\n",
    "#                 self.tensorboard_writer.add_images('bwd_rigid_error_scale' + str(j), tmp, n_iter)\n",
    "#                 self.bwd_rigid_error_scale.append(tmp)\n",
    "\n",
    "    #####################################################################################################\n",
    "    \n",
    "    def build_flownet(self):\n",
    "\n",
    "        # output residual flow\n",
    "        # TODO: non residual mode\n",
    "        #   make input of the flowNet\n",
    "        # cat along the color channels\n",
    "        # shapes: #batch*#src_views, 3+3+3+2+1,h,w\n",
    "\n",
    "        fwd_flownet_inputs = torch.cat(\n",
    "            (self.tgt_view_tile_pyramid[0], self.src_views_pyramid[0],\n",
    "             self.fwd_rigid_warp_pyramid[0], self.fwd_rigid_flow_pyramid[0],\n",
    "             L2_norm(self.fwd_rigid_error_pyramid[0], dim=1)),\n",
    "            dim=1)\n",
    "        bwd_flownet_inputs = torch.cat(\n",
    "            (self.src_views_pyramid[0], self.tgt_view_tile_pyramid[0],\n",
    "             self.bwd_rigid_warp_pyramid[0], self.bwd_rigid_flow_pyramid[0],\n",
    "             L2_norm(self.bwd_rigid_error_pyramid[0], dim=1)),\n",
    "            dim=1)\n",
    "\n",
    "        # shapes: # batch\n",
    "        flownet_inputs = torch.cat((fwd_flownet_inputs, bwd_flownet_inputs),\n",
    "                                   dim=0)\n",
    "\n",
    "        # shape: (#batch*2, (3+3+3+2+1)*#src_views, h,w)\n",
    "        self.resflow = self.flow_net(flownet_inputs)\n",
    "\n",
    "    def build_full_warp_flow(self):\n",
    "        # unnormalize the pyramid flow back to pixel metric\n",
    "        resflow_scaling = []\n",
    "        # for s in range(self.num_scales):\n",
    "        #     batch_size, _, h, w = self.resflow[s].shape\n",
    "        #     # create a scale factor matrix for pointwise multiplication\n",
    "        #     # NOTE: flow channels x,y\n",
    "        #     scale_factor = torch.tensor([w, h]).view(1, 2, 1,\n",
    "        #                                              1).float().to(device)\n",
    "        #     scale_factor = scale_factor.repeat(batch_size, 1, h, w)\n",
    "        #     resflow_scaling.append(self.resflow[s] * scale_factor)\n",
    "\n",
    "        # self.resflow = resflow_scaling\n",
    "\n",
    "        self.fwd_full_flow_pyramid = [\n",
    "            self.resflow[s][:self.batch_size * self.num_source,:,:,:] +\n",
    "            self.fwd_rigid_flow_pyramid[s][:,:,:,:] for s in range(self.num_scales)\n",
    "        ]\n",
    "        self.bwd_full_flow_pyramid = [\n",
    "            self.resflow[s][:self.batch_size * self.num_source,:,:,:] +\n",
    "            self.bwd_rigid_flow_pyramid[s][:,:,:,:] for s in range(self.num_scales)\n",
    "        ]\n",
    "\n",
    "        self.fwd_full_warp_pyramid = [\n",
    "            flow_warp(self.src_views_pyramid[s], self.fwd_full_flow_pyramid[s])\n",
    "            for s in range(self.num_scales)\n",
    "        ]\n",
    "        self.bwd_full_warp_pyramid = [\n",
    "            flow_warp(self.tgt_view_tile_pyramid[s],\n",
    "                      self.bwd_full_flow_pyramid[s])\n",
    "            for s in range(self.num_scales)\n",
    "        ]\n",
    "\n",
    "        self.fwd_full_error_pyramid = [\n",
    "            image_similarity(self.simi_alpha, self.fwd_full_warp_pyramid[s],\n",
    "                             self.tgt_view_tile_pyramid[s])\n",
    "            for s in range(self.num_scales)\n",
    "        ]\n",
    "        self.bwd_full_error_pyramid = [\n",
    "            image_similarity(self.simi_alpha, self.bwd_full_warp_pyramid[s],\n",
    "                             self.src_views_pyramid[s])\n",
    "            for s in range(self.num_scales)\n",
    "        ]\n",
    "\n",
    "    def build_losses(self):\n",
    "        \"\"\"\n",
    "        # NOTE: geometrical consistency\n",
    "        if self.train_flow:\n",
    "            bwd2fwd_flow_pyramid = [\n",
    "                flow_warp(self.bwd_full_flow_pyramid[s],\n",
    "                          self.fwd_full_flow_pyramid[s])\n",
    "                for s in range(self.num_scales)\n",
    "            ]\n",
    "            fwd2bwd_flow_pyramid = [\n",
    "                flow_warp(self.fwd_full_flow_pyramid[s],\n",
    "                          self.bwd_full_flow_pyramid[s])\n",
    "                for s in range(self.num_scales)\n",
    "            ]\n",
    "\n",
    "            fwd_flow_diff_pyramid = [\n",
    "                torch.abs(bwd2fwd_flow_pyramid[s] +\n",
    "                          self.fwd_full_flow_pyramid[s])\n",
    "                for s in range(self.num_scales)\n",
    "            ]\n",
    "            bwd_flow_diff_pyramid = [\n",
    "                torch.abs(fwd2bwd_flow_pyramid[s] +\n",
    "                          self.bwd_full_flow_pyramid[s])\n",
    "                for s in range(self.num_scales)\n",
    "            ]\n",
    "\n",
    "            fwd_consist_bound_pyramid = [\n",
    "                self.geometric_consistency_beta * self.fwd_full_flow_pyramid[s]\n",
    "                * 2**s for s in range(self.num_scales)\n",
    "            ]\n",
    "            bwd_consist_bound_pyramid = [\n",
    "                self.geometric_consistency_beta * self.bwd_full_flow_pyramid[s]\n",
    "                * 2**s for s in range(self.num_scales)\n",
    "            ]\n",
    "            # stop gradient at maximum opeartions\n",
    "            fwd_consist_bound_pyramid = [\n",
    "                torch.max(s,\n",
    "                          self.geometric_consistency_alpha).clone().detach()\n",
    "                for s in fwd_consist_bound_pyramid\n",
    "            ]\n",
    "\n",
    "            bwd_consist_bound_pyramid = [\n",
    "                torch.max(s,\n",
    "                          self.geometric_consistency_alpha).clone().detach()\n",
    "                for s in bwd_consist_bound_pyramid\n",
    "            ]\n",
    "\n",
    "            fwd_mask_pyramid = [(fwd_flow_diff_pyramid[s] * 2**s <\n",
    "                                 fwd_consist_bound_pyramid[s]).float()\n",
    "                                for s in range(self.num_scales)]\n",
    "            bwd_mask_pyramid = [(bwd_flow_diff_pyramid[s] * 2**s <\n",
    "                                 bwd_consist_bound_pyramid[s]).float()\n",
    "                                for s in range(self.num_scales)]\n",
    "        \"\"\"\n",
    "        \n",
    "        # from IPython import embed\n",
    "        # from matplotlib import pyplot as plt\n",
    "        # embed()\n",
    "        # NOTE: loss\n",
    "        if self.train_flow:\n",
    "            self.loss_full_warp = 0\n",
    "            self.loss_full_smooth = 0\n",
    "            self.loss_geometric_consistency = 0\n",
    "\n",
    "        loss_rigid_warp = 0\n",
    "        loss_disp_smooth = 0\n",
    "        \n",
    "        for s in range(self.num_scales):\n",
    "\n",
    "            loss_rigid_warp += self.loss_weight_rigid_warp *\\\n",
    "                self.num_source/2*(\n",
    "                    torch.mean(self.fwd_rigid_error_pyramid[s]) +\n",
    "                    torch.mean(self.bwd_rigid_error_pyramid[s]))\n",
    "\n",
    "#             print(self.loss_disparities[0].size())\n",
    "#             print(torch.cat((self.tgt_view_pyramid[3], self.src_views_pyramid[3]), dim=0).size())\n",
    "            loss_disp_smooth += self.loss_weight_disparity_smooth/(2**s) *\\\n",
    "                smooth_loss(self.loss_disparities[s], torch.cat(\n",
    "                    (self.tgt_view_pyramid[s], self.src_views_pyramid[s]), dim=0))\n",
    "\n",
    "            \"\"\"\n",
    "            if self.train_flow:\n",
    "                self.loss_full_warp += self.loss_weight_full_warp * self.num_source / 2 * (\n",
    "                    torch.sum(\n",
    "                        torch.mean(self.fwd_full_error_pyramid[s], 1, True) *\n",
    "                        fwd_mask_pyramid[s]) / torch.mean(fwd_mask_pyramid[s])\n",
    "                    + torch.sum(\n",
    "                        torch.mean(self.bwd_full_error_pyramid[s], 1, True) *\n",
    "                        bwd_mask_pyramid[s]) / torch.mean(bwd_mask_pyramid[s]))\n",
    "\n",
    "                self.loss_full_smooth += self.loss_weigtht_full_smooth/2**(s+1) *\\\n",
    "                    (flow_smooth_loss(\n",
    "                        self.fwd_full_flow_pyramid[s], self.tgt_view_tile_pyramid[s]) +\n",
    "                        flow_smooth_loss(self.bwd_full_flow_pyramid[s], self.src_views_pyramid[s]))\n",
    "\n",
    "                self.loss_geometric_consistency += self.loss_weight_geometrical_consistency / 2 * (\n",
    "                    torch.sum(\n",
    "                        torch.mean(fwd_flow_diff_pyramid[s], 1, True) *\n",
    "                        fwd_mask_pyramid[s]) / torch.mean(fwd_mask_pyramid[s])\n",
    "                    + torch.sum(\n",
    "                        torch.mean(bwd_flow_diff_pyramid[s], 1, True) *\n",
    "                        bwd_mask_pyramid[s]) / torch.mean(bwd_mask_pyramid[s]))\n",
    "            \"\"\"\n",
    "        self.loss_rigid_warp = 0\n",
    "        self.loss_disp_smooth = 0\n",
    "        self.loss_total = 0\n",
    "        \n",
    "        self.loss_rigid_warp += loss_rigid_warp\n",
    "        self.loss_disp_smooth += loss_disp_smooth\n",
    "        self.loss_total += loss_rigid_warp + loss_disp_smooth\n",
    "        \n",
    "        print(self.loss_rigid_warp, self.loss_disp_smooth)\n",
    "        \"\"\"\n",
    "        if self.train_flow:\n",
    "            print('full warp: {} full_smooth: {}, geo_con:{}'.format(self.loss_full_warp,self.loss_full_smooth,self.loss_geometric_consistency))\n",
    "            self.loss_total += self.loss_full_warp + \\\n",
    "                self.loss_full_smooth + self.loss_geometric_consistency\n",
    "        \"\"\"\n",
    "        \n",
    "    def training_inside_epoch(self):\n",
    "        global n_iter\n",
    "\n",
    "        print(\"Length of train loader: {}\".format(len(self.train_loader)))\n",
    "        for i, sampled_batch in enumerate(self.train_loader):\n",
    "            \"\"\"\n",
    "            Length of train_loader: num_sequences/4\n",
    "            Length of sampled_batch: 3\n",
    "            sampled_batch[i] : [batch_size, channels, height, width]\n",
    "            \"\"\"\n",
    "            start = time.time()\n",
    "            \n",
    "            self.iter_data_preparation(sampled_batch)           \n",
    "            \n",
    "            self.build_dispnet()\n",
    "            self.build_posenet()\n",
    "            \n",
    "            self.build_rigid_warp_flow()\n",
    "            \n",
    "            if self.train_flow:\n",
    "                self.build_flownet()\n",
    "                self.build_full_warp_flow()\n",
    "            \n",
    "            self.build_losses()\n",
    "\n",
    "            \"\"\"\n",
    "            if torch.cuda.is_available(): \n",
    "                print(torch.cuda.get_device_name(0))\n",
    "                print('Memory Usage:')\n",
    "                print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "                print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "            \"\"\"\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            self.loss_total.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    " \n",
    "            if n_iter % 100 == 0:\n",
    "                print('Iteration: {} \\t Rigid-warp: {:.4f} \\t Disp-smooth: {:.6f}\\tTime: {:.3f}'.format(n_iter, self.loss_rigid_warp.item(), self.loss_disp_smooth.item(), time.time() - start))\n",
    "\n",
    "#                 self.tensorboard_writer.add_scalar('total_loss', self.loss_total.item(), n_iter)\n",
    "#                 self.tensorboard_writer.add_scalar('rigid_warp_loss', self.loss_rigid_warp.item(), n_iter)\n",
    "#                 self.tensorboard_writer.add_scalar('disp_smooth_loss', self.loss_disp_smooth.item(), n_iter)\n",
    "\n",
    "            if n_iter % self.output_ckpt_iter == 0 and n_iter != 0:\n",
    "                path = '{}/{}_{}'.format(self.config['ckpt_dir'], 'flow' if self.train_flow else 'rigid_depth', str(n_iter)+'.pth')\n",
    "                \n",
    "                torch.save({\n",
    "                    'iter': i,\n",
    "                    'disp_net_state_dict': self.disp_net.state_dict(),\n",
    "                    'pose_net_state_dict': self.pose_net.state_dict(),\n",
    "                    'loss': self.loss_total\n",
    "                }, path)\n",
    "            \n",
    "            n_iter += 1\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        global n_iter\n",
    "\n",
    "        # Sets mode of models to 'train'\n",
    "        if not self.train_flow:\n",
    "            self.pose_net.train()\n",
    "            self.disp_net.train()\n",
    "        \n",
    "        print('Constructing dataset object...')\n",
    "        self.train_set = SequenceFolder(\n",
    "            self.config['data'],\n",
    "            transform=None,\n",
    "            split='train',\n",
    "            seed=self.config['seed'],\n",
    "            img_height=self.config['img_height'],\n",
    "            img_width=self.config['img_width'],\n",
    "            sequence_length=self.config['sequence_length'])\n",
    "\n",
    "        #TODO: TURN SHUFFLE ON LATER\n",
    "        print('Constructing dataloader object...')\n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            self.train_set,\n",
    "            shuffle=False,\n",
    "            drop_last=True,\n",
    "            num_workers=self.config['data_workers'],\n",
    "            batch_size=self.config['batch_size'],\n",
    "            pin_memory=False)\n",
    "\n",
    "        optim_params = [{\n",
    "            'params': v.parameters(),\n",
    "            'lr': self.config['learning_rate']\n",
    "        } for v in self.nets.values()]\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            optim_params,\n",
    "            betas=(self.config['momentum'], self.config['beta']),\n",
    "            weight_decay=self.config['weight_decay'])\n",
    "        \n",
    "        print('Starting training for {} epochs...'.format(self.epochs))\n",
    "        for epoch in range(self.epochs):\n",
    "            print('-------------------------------EPOCH {}---------------------------------'.format(epoch))\n",
    "            self.training_inside_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA NOT available\n",
      "Initializing weights from scratch\n",
      "Writing graphs to /ceph/raunaks/lsd-signet/reconstruction/graphs/debuggy\n",
      "Constructing dataset object...\n",
      "Constructing dataloader object...\n",
      "Starting training for 1 epochs...\n",
      "-------------------------------EPOCH 0---------------------------------\n",
      "Length of train loader: 1\n",
      "torch.Size([12, 128, 416, 1]) tensor(7.3028, grad_fn=<MeanBackward0>) [tensor([[[[2.6876],\n",
      "          [4.3354],\n",
      "          [4.4787],\n",
      "          ...,\n",
      "          [4.1739],\n",
      "          [4.7686],\n",
      "          [5.3710]],\n",
      "\n",
      "         [[4.5229],\n",
      "          [7.3836],\n",
      "          [7.1673],\n",
      "          ...,\n",
      "          [6.7942],\n",
      "          [6.6917],\n",
      "          [6.5823]],\n",
      "\n",
      "         [[4.5570],\n",
      "          [7.4136],\n",
      "          [7.3733],\n",
      "          ...,\n",
      "          [6.9960],\n",
      "          [6.8234],\n",
      "          [6.6408]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.2877],\n",
      "          [7.7056],\n",
      "          [7.2869],\n",
      "          ...,\n",
      "          [7.2719],\n",
      "          [6.9794],\n",
      "          [6.8578]],\n",
      "\n",
      "         [[3.6867],\n",
      "          [6.6610],\n",
      "          [6.4885],\n",
      "          ...,\n",
      "          [6.4379],\n",
      "          [6.4398],\n",
      "          [6.5651]],\n",
      "\n",
      "         [[6.3977],\n",
      "          [6.6600],\n",
      "          [7.7098],\n",
      "          ...,\n",
      "          [7.3613],\n",
      "          [6.6491],\n",
      "          [6.3181]]],\n",
      "\n",
      "\n",
      "        [[[2.6925],\n",
      "          [4.3980],\n",
      "          [4.4956],\n",
      "          ...,\n",
      "          [4.1737],\n",
      "          [4.7726],\n",
      "          [5.3707]],\n",
      "\n",
      "         [[4.4896],\n",
      "          [7.4054],\n",
      "          [7.1479],\n",
      "          ...,\n",
      "          [6.7752],\n",
      "          [6.6866],\n",
      "          [6.5806]],\n",
      "\n",
      "         [[4.5087],\n",
      "          [7.4598],\n",
      "          [7.3421],\n",
      "          ...,\n",
      "          [6.9752],\n",
      "          [6.8110],\n",
      "          [6.6423]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.2869],\n",
      "          [7.7078],\n",
      "          [7.2918],\n",
      "          ...,\n",
      "          [7.2732],\n",
      "          [6.9956],\n",
      "          [6.8510]],\n",
      "\n",
      "         [[3.6804],\n",
      "          [6.6573],\n",
      "          [6.4770],\n",
      "          ...,\n",
      "          [6.4488],\n",
      "          [6.4301],\n",
      "          [6.5589]],\n",
      "\n",
      "         [[6.4001],\n",
      "          [6.6626],\n",
      "          [7.7136],\n",
      "          ...,\n",
      "          [7.3644],\n",
      "          [6.6582],\n",
      "          [6.3178]]],\n",
      "\n",
      "\n",
      "        [[[2.6940],\n",
      "          [4.3416],\n",
      "          [4.4834],\n",
      "          ...,\n",
      "          [4.1759],\n",
      "          [4.7729],\n",
      "          [5.3713]],\n",
      "\n",
      "         [[4.5144],\n",
      "          [7.3729],\n",
      "          [7.1585],\n",
      "          ...,\n",
      "          [6.7758],\n",
      "          [6.6857],\n",
      "          [6.5808]],\n",
      "\n",
      "         [[4.5532],\n",
      "          [7.4124],\n",
      "          [7.3640],\n",
      "          ...,\n",
      "          [6.9768],\n",
      "          [6.8115],\n",
      "          [6.6422]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.2856],\n",
      "          [7.7005],\n",
      "          [7.2885],\n",
      "          ...,\n",
      "          [7.2847],\n",
      "          [6.9871],\n",
      "          [6.8614]],\n",
      "\n",
      "         [[3.6563],\n",
      "          [6.6452],\n",
      "          [6.4626],\n",
      "          ...,\n",
      "          [6.4468],\n",
      "          [6.4358],\n",
      "          [6.5629]],\n",
      "\n",
      "         [[6.4017],\n",
      "          [6.6700],\n",
      "          [7.7111],\n",
      "          ...,\n",
      "          [7.3698],\n",
      "          [6.6495],\n",
      "          [6.3183]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2.6945],\n",
      "          [4.4010],\n",
      "          [4.5005],\n",
      "          ...,\n",
      "          [4.1777],\n",
      "          [4.7759],\n",
      "          [5.3711]],\n",
      "\n",
      "         [[4.4855],\n",
      "          [7.4082],\n",
      "          [7.1444],\n",
      "          ...,\n",
      "          [6.7742],\n",
      "          [6.6833],\n",
      "          [6.5790]],\n",
      "\n",
      "         [[4.5024],\n",
      "          [7.4622],\n",
      "          [7.3398],\n",
      "          ...,\n",
      "          [6.9800],\n",
      "          [6.8097],\n",
      "          [6.6406]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.2764],\n",
      "          [7.7028],\n",
      "          [7.2647],\n",
      "          ...,\n",
      "          [7.2784],\n",
      "          [6.9895],\n",
      "          [6.8590]],\n",
      "\n",
      "         [[3.6712],\n",
      "          [6.6517],\n",
      "          [6.4833],\n",
      "          ...,\n",
      "          [6.4492],\n",
      "          [6.4371],\n",
      "          [6.5634]],\n",
      "\n",
      "         [[6.3905],\n",
      "          [6.6693],\n",
      "          [7.7151],\n",
      "          ...,\n",
      "          [7.3687],\n",
      "          [6.6558],\n",
      "          [6.3200]]],\n",
      "\n",
      "\n",
      "        [[[2.6923],\n",
      "          [4.3413],\n",
      "          [4.4775],\n",
      "          ...,\n",
      "          [4.1760],\n",
      "          [4.7720],\n",
      "          [5.3712]],\n",
      "\n",
      "         [[4.5160],\n",
      "          [7.3766],\n",
      "          [7.1609],\n",
      "          ...,\n",
      "          [6.7747],\n",
      "          [6.6850],\n",
      "          [6.5802]],\n",
      "\n",
      "         [[4.5460],\n",
      "          [7.4133],\n",
      "          [7.3659],\n",
      "          ...,\n",
      "          [6.9753],\n",
      "          [6.8108],\n",
      "          [6.6417]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.2846],\n",
      "          [7.6977],\n",
      "          [7.2864],\n",
      "          ...,\n",
      "          [7.2890],\n",
      "          [6.9893],\n",
      "          [6.8627]],\n",
      "\n",
      "         [[3.6657],\n",
      "          [6.6474],\n",
      "          [6.4594],\n",
      "          ...,\n",
      "          [6.4494],\n",
      "          [6.4395],\n",
      "          [6.5632]],\n",
      "\n",
      "         [[6.4010],\n",
      "          [6.6641],\n",
      "          [7.7103],\n",
      "          ...,\n",
      "          [7.3735],\n",
      "          [6.6584],\n",
      "          [6.3236]]],\n",
      "\n",
      "\n",
      "        [[[2.6902],\n",
      "          [4.3422],\n",
      "          [4.4825],\n",
      "          ...,\n",
      "          [4.1672],\n",
      "          [4.7775],\n",
      "          [5.3429]],\n",
      "\n",
      "         [[4.5185],\n",
      "          [7.3767],\n",
      "          [7.1645],\n",
      "          ...,\n",
      "          [6.8017],\n",
      "          [6.7147],\n",
      "          [6.5614]],\n",
      "\n",
      "         [[4.5480],\n",
      "          [7.4132],\n",
      "          [7.3664],\n",
      "          ...,\n",
      "          [7.0308],\n",
      "          [6.8109],\n",
      "          [6.6297]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.2868],\n",
      "          [7.7070],\n",
      "          [7.2900],\n",
      "          ...,\n",
      "          [7.2742],\n",
      "          [6.9813],\n",
      "          [6.8582]],\n",
      "\n",
      "         [[3.6797],\n",
      "          [6.6595],\n",
      "          [6.4773],\n",
      "          ...,\n",
      "          [6.4389],\n",
      "          [6.4336],\n",
      "          [6.5707]],\n",
      "\n",
      "         [[6.3992],\n",
      "          [6.6652],\n",
      "          [7.7135],\n",
      "          ...,\n",
      "          [7.3659],\n",
      "          [6.6473],\n",
      "          [6.3198]]]], grad_fn=<UnsqueezeBackward0>), tensor([[[[5.7378],\n",
      "          [4.7728],\n",
      "          [4.9227],\n",
      "          ...,\n",
      "          [4.4892],\n",
      "          [4.1032],\n",
      "          [4.5272]],\n",
      "\n",
      "         [[5.7546],\n",
      "          [5.1294],\n",
      "          [4.6913],\n",
      "          ...,\n",
      "          [4.9526],\n",
      "          [4.3136],\n",
      "          [4.9420]],\n",
      "\n",
      "         [[6.8458],\n",
      "          [4.8862],\n",
      "          [5.6633],\n",
      "          ...,\n",
      "          [5.3875],\n",
      "          [4.8081],\n",
      "          [4.8569]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.5581],\n",
      "          [5.4626],\n",
      "          [5.5706],\n",
      "          ...,\n",
      "          [5.6504],\n",
      "          [4.7347],\n",
      "          [5.0374]],\n",
      "\n",
      "         [[6.2123],\n",
      "          [5.2952],\n",
      "          [5.7465],\n",
      "          ...,\n",
      "          [5.6367],\n",
      "          [4.5702],\n",
      "          [5.0855]],\n",
      "\n",
      "         [[6.2766],\n",
      "          [5.2848],\n",
      "          [5.5002],\n",
      "          ...,\n",
      "          [5.5264],\n",
      "          [5.0849],\n",
      "          [4.9632]]],\n",
      "\n",
      "\n",
      "        [[[5.7270],\n",
      "          [4.6354],\n",
      "          [4.8636],\n",
      "          ...,\n",
      "          [4.4863],\n",
      "          [4.0787],\n",
      "          [4.5187]],\n",
      "\n",
      "         [[5.9026],\n",
      "          [5.2556],\n",
      "          [4.7740],\n",
      "          ...,\n",
      "          [4.9486],\n",
      "          [4.2636],\n",
      "          [4.9417]],\n",
      "\n",
      "         [[7.1214],\n",
      "          [5.1238],\n",
      "          [6.0740],\n",
      "          ...,\n",
      "          [5.2925],\n",
      "          [4.6902],\n",
      "          [4.8602]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.5670],\n",
      "          [5.4735],\n",
      "          [5.5717],\n",
      "          ...,\n",
      "          [5.6799],\n",
      "          [4.8140],\n",
      "          [5.0280]],\n",
      "\n",
      "         [[6.1971],\n",
      "          [5.3034],\n",
      "          [5.7347],\n",
      "          ...,\n",
      "          [5.5139],\n",
      "          [4.6014],\n",
      "          [5.0606]],\n",
      "\n",
      "         [[6.2815],\n",
      "          [5.3116],\n",
      "          [5.5296],\n",
      "          ...,\n",
      "          [5.5156],\n",
      "          [5.0918],\n",
      "          [4.9647]]],\n",
      "\n",
      "\n",
      "        [[[5.7110],\n",
      "          [4.7740],\n",
      "          [4.8783],\n",
      "          ...,\n",
      "          [4.5058],\n",
      "          [4.0923],\n",
      "          [4.5166]],\n",
      "\n",
      "         [[5.7635],\n",
      "          [5.1324],\n",
      "          [4.6679],\n",
      "          ...,\n",
      "          [4.9421],\n",
      "          [4.2546],\n",
      "          [4.9410]],\n",
      "\n",
      "         [[6.8303],\n",
      "          [4.8301],\n",
      "          [5.5996],\n",
      "          ...,\n",
      "          [5.2663],\n",
      "          [4.7051],\n",
      "          [4.8630]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.5235],\n",
      "          [5.3720],\n",
      "          [5.4571],\n",
      "          ...,\n",
      "          [5.7439],\n",
      "          [4.7692],\n",
      "          [5.0153]],\n",
      "\n",
      "         [[6.1484],\n",
      "          [5.1975],\n",
      "          [5.6697],\n",
      "          ...,\n",
      "          [5.6312],\n",
      "          [4.5972],\n",
      "          [5.0837]],\n",
      "\n",
      "         [[6.3082],\n",
      "          [5.2962],\n",
      "          [5.5569],\n",
      "          ...,\n",
      "          [5.5825],\n",
      "          [5.0711],\n",
      "          [4.9487]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[5.7225],\n",
      "          [4.6227],\n",
      "          [4.8567],\n",
      "          ...,\n",
      "          [4.5025],\n",
      "          [4.0827],\n",
      "          [4.5066]],\n",
      "\n",
      "         [[5.9219],\n",
      "          [5.2440],\n",
      "          [4.7694],\n",
      "          ...,\n",
      "          [4.9592],\n",
      "          [4.2617],\n",
      "          [4.9251]],\n",
      "\n",
      "         [[7.1330],\n",
      "          [5.1098],\n",
      "          [6.0760],\n",
      "          ...,\n",
      "          [5.2742],\n",
      "          [4.7042],\n",
      "          [4.8582]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.4860],\n",
      "          [5.4344],\n",
      "          [5.5731],\n",
      "          ...,\n",
      "          [5.6880],\n",
      "          [4.7755],\n",
      "          [5.0196]],\n",
      "\n",
      "         [[6.1589],\n",
      "          [5.1637],\n",
      "          [5.5176],\n",
      "          ...,\n",
      "          [5.5804],\n",
      "          [4.6014],\n",
      "          [5.0805]],\n",
      "\n",
      "         [[6.3037],\n",
      "          [5.2551],\n",
      "          [5.5183],\n",
      "          ...,\n",
      "          [5.5458],\n",
      "          [5.0965],\n",
      "          [4.9648]]],\n",
      "\n",
      "\n",
      "        [[[5.7154],\n",
      "          [4.7713],\n",
      "          [4.9092],\n",
      "          ...,\n",
      "          [4.4994],\n",
      "          [4.0870],\n",
      "          [4.5171]],\n",
      "\n",
      "         [[5.7560],\n",
      "          [5.1462],\n",
      "          [4.6839],\n",
      "          ...,\n",
      "          [4.9439],\n",
      "          [4.2541],\n",
      "          [4.9401]],\n",
      "\n",
      "         [[6.8562],\n",
      "          [4.8916],\n",
      "          [5.6593],\n",
      "          ...,\n",
      "          [5.2666],\n",
      "          [4.7016],\n",
      "          [4.8579]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.5298],\n",
      "          [5.4044],\n",
      "          [5.5210],\n",
      "          ...,\n",
      "          [5.6960],\n",
      "          [4.7950],\n",
      "          [5.0085]],\n",
      "\n",
      "         [[6.1604],\n",
      "          [5.2243],\n",
      "          [5.6538],\n",
      "          ...,\n",
      "          [5.6033],\n",
      "          [4.5983],\n",
      "          [5.0814]],\n",
      "\n",
      "         [[6.2903],\n",
      "          [5.3132],\n",
      "          [5.5423],\n",
      "          ...,\n",
      "          [5.5530],\n",
      "          [5.1092],\n",
      "          [4.9675]]],\n",
      "\n",
      "\n",
      "        [[[5.7258],\n",
      "          [4.7645],\n",
      "          [4.9094],\n",
      "          ...,\n",
      "          [4.3611],\n",
      "          [3.9791],\n",
      "          [4.4209]],\n",
      "\n",
      "         [[5.7630],\n",
      "          [5.1501],\n",
      "          [4.6883],\n",
      "          ...,\n",
      "          [5.0723],\n",
      "          [4.3950],\n",
      "          [4.7994]],\n",
      "\n",
      "         [[6.8493],\n",
      "          [4.8799],\n",
      "          [5.6308],\n",
      "          ...,\n",
      "          [5.6324],\n",
      "          [4.9224],\n",
      "          [4.8265]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.5707],\n",
      "          [5.4672],\n",
      "          [5.5646],\n",
      "          ...,\n",
      "          [5.6716],\n",
      "          [4.7194],\n",
      "          [5.0148]],\n",
      "\n",
      "         [[6.2027],\n",
      "          [5.2909],\n",
      "          [5.7472],\n",
      "          ...,\n",
      "          [5.6356],\n",
      "          [4.5786],\n",
      "          [5.0989]],\n",
      "\n",
      "         [[6.2875],\n",
      "          [5.3044],\n",
      "          [5.5399],\n",
      "          ...,\n",
      "          [5.5583],\n",
      "          [5.0817],\n",
      "          [4.9709]]]], grad_fn=<UnsqueezeBackward0>), tensor([[[[4.8243],\n",
      "          [5.2228],\n",
      "          [5.1666],\n",
      "          ...,\n",
      "          [5.1608],\n",
      "          [5.5771],\n",
      "          [5.3043]],\n",
      "\n",
      "         [[4.8162],\n",
      "          [4.8511],\n",
      "          [4.9051],\n",
      "          ...,\n",
      "          [4.8569],\n",
      "          [4.9014],\n",
      "          [4.9885]],\n",
      "\n",
      "         [[4.8308],\n",
      "          [5.0471],\n",
      "          [5.2304],\n",
      "          ...,\n",
      "          [5.1971],\n",
      "          [5.3064],\n",
      "          [5.1381]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.8008],\n",
      "          [5.0175],\n",
      "          [5.1549],\n",
      "          ...,\n",
      "          [5.2382],\n",
      "          [5.3557],\n",
      "          [5.1530]],\n",
      "\n",
      "         [[4.5151],\n",
      "          [4.4741],\n",
      "          [4.6251],\n",
      "          ...,\n",
      "          [4.6394],\n",
      "          [4.6723],\n",
      "          [4.6881]],\n",
      "\n",
      "         [[4.8572],\n",
      "          [4.4132],\n",
      "          [4.4849],\n",
      "          ...,\n",
      "          [4.5774],\n",
      "          [4.5316],\n",
      "          [4.4851]]],\n",
      "\n",
      "\n",
      "        [[[4.8469],\n",
      "          [5.2539],\n",
      "          [5.2148],\n",
      "          ...,\n",
      "          [5.2014],\n",
      "          [5.5782],\n",
      "          [5.3255]],\n",
      "\n",
      "         [[4.7770],\n",
      "          [4.8475],\n",
      "          [4.9412],\n",
      "          ...,\n",
      "          [4.8586],\n",
      "          [4.9620],\n",
      "          [4.9986]],\n",
      "\n",
      "         [[4.7812],\n",
      "          [5.0038],\n",
      "          [5.1641],\n",
      "          ...,\n",
      "          [5.1853],\n",
      "          [5.3296],\n",
      "          [5.1942]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.8021],\n",
      "          [5.0450],\n",
      "          [5.1877],\n",
      "          ...,\n",
      "          [5.1971],\n",
      "          [5.3366],\n",
      "          [5.1545]],\n",
      "\n",
      "         [[4.5044],\n",
      "          [4.4752],\n",
      "          [4.6393],\n",
      "          ...,\n",
      "          [4.6388],\n",
      "          [4.6946],\n",
      "          [4.7066]],\n",
      "\n",
      "         [[4.8585],\n",
      "          [4.4415],\n",
      "          [4.5052],\n",
      "          ...,\n",
      "          [4.6147],\n",
      "          [4.5609],\n",
      "          [4.4976]]],\n",
      "\n",
      "\n",
      "        [[[4.8346],\n",
      "          [5.2273],\n",
      "          [5.1470],\n",
      "          ...,\n",
      "          [5.2018],\n",
      "          [5.5776],\n",
      "          [5.3319]],\n",
      "\n",
      "         [[4.8371],\n",
      "          [4.8594],\n",
      "          [4.8970],\n",
      "          ...,\n",
      "          [4.8490],\n",
      "          [4.9463],\n",
      "          [4.9921]],\n",
      "\n",
      "         [[4.8255],\n",
      "          [5.0596],\n",
      "          [5.2510],\n",
      "          ...,\n",
      "          [5.1694],\n",
      "          [5.3231],\n",
      "          [5.1885]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.8107],\n",
      "          [4.9874],\n",
      "          [5.1678],\n",
      "          ...,\n",
      "          [5.2620],\n",
      "          [5.3980],\n",
      "          [5.1882]],\n",
      "\n",
      "         [[4.4985],\n",
      "          [4.4741],\n",
      "          [4.6815],\n",
      "          ...,\n",
      "          [4.6639],\n",
      "          [4.7271],\n",
      "          [4.7118]],\n",
      "\n",
      "         [[4.8675],\n",
      "          [4.4430],\n",
      "          [4.5097],\n",
      "          ...,\n",
      "          [4.5878],\n",
      "          [4.5652],\n",
      "          [4.4978]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[4.8550],\n",
      "          [5.2672],\n",
      "          [5.1730],\n",
      "          ...,\n",
      "          [5.2047],\n",
      "          [5.5793],\n",
      "          [5.3291]],\n",
      "\n",
      "         [[4.7942],\n",
      "          [4.8577],\n",
      "          [4.9426],\n",
      "          ...,\n",
      "          [4.8460],\n",
      "          [4.9601],\n",
      "          [5.0007]],\n",
      "\n",
      "         [[4.7649],\n",
      "          [5.0161],\n",
      "          [5.1936],\n",
      "          ...,\n",
      "          [5.1899],\n",
      "          [5.3303],\n",
      "          [5.1917]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.7868],\n",
      "          [4.9907],\n",
      "          [5.2593],\n",
      "          ...,\n",
      "          [5.2050],\n",
      "          [5.3464],\n",
      "          [5.1553]],\n",
      "\n",
      "         [[4.5386],\n",
      "          [4.4405],\n",
      "          [4.8054],\n",
      "          ...,\n",
      "          [4.6472],\n",
      "          [4.6917],\n",
      "          [4.7014]],\n",
      "\n",
      "         [[4.9150],\n",
      "          [4.4972],\n",
      "          [4.6005],\n",
      "          ...,\n",
      "          [4.5828],\n",
      "          [4.5449],\n",
      "          [4.4901]]],\n",
      "\n",
      "\n",
      "        [[[4.8310],\n",
      "          [5.2187],\n",
      "          [5.1538],\n",
      "          ...,\n",
      "          [5.2026],\n",
      "          [5.5799],\n",
      "          [5.3290]],\n",
      "\n",
      "         [[4.8296],\n",
      "          [4.8565],\n",
      "          [4.9035],\n",
      "          ...,\n",
      "          [4.8571],\n",
      "          [4.9505],\n",
      "          [4.9884]],\n",
      "\n",
      "         [[4.8000],\n",
      "          [5.0645],\n",
      "          [5.2260],\n",
      "          ...,\n",
      "          [5.1862],\n",
      "          [5.3205],\n",
      "          [5.1932]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.7996],\n",
      "          [4.9973],\n",
      "          [5.1797],\n",
      "          ...,\n",
      "          [5.2698],\n",
      "          [5.3869],\n",
      "          [5.1991]],\n",
      "\n",
      "         [[4.4948],\n",
      "          [4.4682],\n",
      "          [4.6641],\n",
      "          ...,\n",
      "          [4.6741],\n",
      "          [4.7311],\n",
      "          [4.7117]],\n",
      "\n",
      "         [[4.8718],\n",
      "          [4.4360],\n",
      "          [4.5070],\n",
      "          ...,\n",
      "          [4.5823],\n",
      "          [4.5624],\n",
      "          [4.4968]]],\n",
      "\n",
      "\n",
      "        [[[4.8298],\n",
      "          [5.2315],\n",
      "          [5.1479],\n",
      "          ...,\n",
      "          [5.1838],\n",
      "          [5.5489],\n",
      "          [5.2078]],\n",
      "\n",
      "         [[4.8312],\n",
      "          [4.8516],\n",
      "          [4.8975],\n",
      "          ...,\n",
      "          [4.8652],\n",
      "          [4.9727],\n",
      "          [4.9213]],\n",
      "\n",
      "         [[4.8058],\n",
      "          [5.0525],\n",
      "          [5.2424],\n",
      "          ...,\n",
      "          [5.1243],\n",
      "          [5.2450],\n",
      "          [5.0597]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.7979],\n",
      "          [5.0222],\n",
      "          [5.1710],\n",
      "          ...,\n",
      "          [5.1990],\n",
      "          [5.3218],\n",
      "          [5.1161]],\n",
      "\n",
      "         [[4.5059],\n",
      "          [4.4809],\n",
      "          [4.6565],\n",
      "          ...,\n",
      "          [4.6280],\n",
      "          [4.6606],\n",
      "          [4.6583]],\n",
      "\n",
      "         [[4.8728],\n",
      "          [4.4270],\n",
      "          [4.4872],\n",
      "          ...,\n",
      "          [4.5621],\n",
      "          [4.5193],\n",
      "          [4.4685]]]], grad_fn=<UnsqueezeBackward0>), tensor([[[[5.0265],\n",
      "          [5.0300],\n",
      "          [5.0428],\n",
      "          ...,\n",
      "          [5.0515],\n",
      "          [5.0450],\n",
      "          [5.0029]],\n",
      "\n",
      "         [[5.0154],\n",
      "          [5.0323],\n",
      "          [5.0275],\n",
      "          ...,\n",
      "          [5.0424],\n",
      "          [5.0210],\n",
      "          [4.9851]],\n",
      "\n",
      "         [[5.0067],\n",
      "          [4.9951],\n",
      "          [4.9957],\n",
      "          ...,\n",
      "          [5.0252],\n",
      "          [5.0275],\n",
      "          [4.9978]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5.0101],\n",
      "          [5.0030],\n",
      "          [5.0122],\n",
      "          ...,\n",
      "          [5.0287],\n",
      "          [5.0258],\n",
      "          [4.9895]],\n",
      "\n",
      "         [[5.0102],\n",
      "          [5.0178],\n",
      "          [5.0102],\n",
      "          ...,\n",
      "          [5.0080],\n",
      "          [4.9974],\n",
      "          [4.9978]],\n",
      "\n",
      "         [[5.0093],\n",
      "          [5.0085],\n",
      "          [5.0057],\n",
      "          ...,\n",
      "          [5.0139],\n",
      "          [5.0006],\n",
      "          [5.0056]]],\n",
      "\n",
      "\n",
      "        [[[5.0259],\n",
      "          [5.0132],\n",
      "          [5.0341],\n",
      "          ...,\n",
      "          [5.0657],\n",
      "          [5.0531],\n",
      "          [4.9989]],\n",
      "\n",
      "         [[5.0340],\n",
      "          [5.0210],\n",
      "          [5.0365],\n",
      "          ...,\n",
      "          [5.0407],\n",
      "          [5.0347],\n",
      "          [4.9905]],\n",
      "\n",
      "         [[5.0056],\n",
      "          [4.9887],\n",
      "          [5.0237],\n",
      "          ...,\n",
      "          [5.0344],\n",
      "          [5.0204],\n",
      "          [4.9838]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5.0163],\n",
      "          [4.9994],\n",
      "          [4.9965],\n",
      "          ...,\n",
      "          [5.0300],\n",
      "          [5.0161],\n",
      "          [4.9832]],\n",
      "\n",
      "         [[5.0161],\n",
      "          [5.0057],\n",
      "          [5.0012],\n",
      "          ...,\n",
      "          [5.0146],\n",
      "          [5.0011],\n",
      "          [4.9954]],\n",
      "\n",
      "         [[5.0022],\n",
      "          [4.9994],\n",
      "          [4.9866],\n",
      "          ...,\n",
      "          [5.0086],\n",
      "          [5.0068],\n",
      "          [5.0050]]],\n",
      "\n",
      "\n",
      "        [[[5.0245],\n",
      "          [5.0256],\n",
      "          [5.0376],\n",
      "          ...,\n",
      "          [5.0586],\n",
      "          [5.0524],\n",
      "          [4.9993]],\n",
      "\n",
      "         [[5.0210],\n",
      "          [5.0285],\n",
      "          [5.0411],\n",
      "          ...,\n",
      "          [5.0468],\n",
      "          [5.0370],\n",
      "          [5.0014]],\n",
      "\n",
      "         [[5.0109],\n",
      "          [4.9919],\n",
      "          [5.0144],\n",
      "          ...,\n",
      "          [5.0239],\n",
      "          [5.0228],\n",
      "          [4.9829]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5.0189],\n",
      "          [5.0123],\n",
      "          [4.9976],\n",
      "          ...,\n",
      "          [5.0409],\n",
      "          [5.0236],\n",
      "          [4.9909]],\n",
      "\n",
      "         [[5.0176],\n",
      "          [4.9973],\n",
      "          [5.0045],\n",
      "          ...,\n",
      "          [5.0159],\n",
      "          [5.0101],\n",
      "          [4.9934]],\n",
      "\n",
      "         [[5.0031],\n",
      "          [5.0087],\n",
      "          [5.0027],\n",
      "          ...,\n",
      "          [5.0119],\n",
      "          [5.0040],\n",
      "          [5.0101]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[5.0175],\n",
      "          [5.0216],\n",
      "          [5.0370],\n",
      "          ...,\n",
      "          [5.0648],\n",
      "          [5.0545],\n",
      "          [4.9954]],\n",
      "\n",
      "         [[5.0251],\n",
      "          [5.0371],\n",
      "          [5.0306],\n",
      "          ...,\n",
      "          [5.0450],\n",
      "          [5.0358],\n",
      "          [4.9924]],\n",
      "\n",
      "         [[5.0040],\n",
      "          [5.0162],\n",
      "          [5.0203],\n",
      "          ...,\n",
      "          [5.0240],\n",
      "          [5.0220],\n",
      "          [4.9836]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5.0226],\n",
      "          [5.0292],\n",
      "          [5.0131],\n",
      "          ...,\n",
      "          [5.0341],\n",
      "          [5.0181],\n",
      "          [4.9844]],\n",
      "\n",
      "         [[5.0235],\n",
      "          [4.9930],\n",
      "          [4.9900],\n",
      "          ...,\n",
      "          [5.0135],\n",
      "          [5.0022],\n",
      "          [4.9945]],\n",
      "\n",
      "         [[4.9811],\n",
      "          [4.9733],\n",
      "          [4.9868],\n",
      "          ...,\n",
      "          [5.0047],\n",
      "          [5.0074],\n",
      "          [5.0040]]],\n",
      "\n",
      "\n",
      "        [[[5.0260],\n",
      "          [5.0349],\n",
      "          [5.0435],\n",
      "          ...,\n",
      "          [5.0638],\n",
      "          [5.0524],\n",
      "          [5.0010]],\n",
      "\n",
      "         [[5.0206],\n",
      "          [5.0252],\n",
      "          [5.0296],\n",
      "          ...,\n",
      "          [5.0431],\n",
      "          [5.0374],\n",
      "          [4.9935]],\n",
      "\n",
      "         [[5.0100],\n",
      "          [5.0093],\n",
      "          [5.0183],\n",
      "          ...,\n",
      "          [5.0227],\n",
      "          [5.0195],\n",
      "          [4.9810]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5.0198],\n",
      "          [5.0165],\n",
      "          [5.0065],\n",
      "          ...,\n",
      "          [5.0416],\n",
      "          [5.0207],\n",
      "          [4.9878]],\n",
      "\n",
      "         [[5.0158],\n",
      "          [4.9952],\n",
      "          [5.0039],\n",
      "          ...,\n",
      "          [5.0209],\n",
      "          [5.0113],\n",
      "          [4.9959]],\n",
      "\n",
      "         [[4.9989],\n",
      "          [5.0084],\n",
      "          [5.0045],\n",
      "          ...,\n",
      "          [5.0084],\n",
      "          [5.0023],\n",
      "          [5.0103]]],\n",
      "\n",
      "\n",
      "        [[[5.0201],\n",
      "          [5.0311],\n",
      "          [5.0372],\n",
      "          ...,\n",
      "          [5.0039],\n",
      "          [5.0063],\n",
      "          [4.9968]],\n",
      "\n",
      "         [[5.0209],\n",
      "          [5.0207],\n",
      "          [5.0250],\n",
      "          ...,\n",
      "          [5.0179],\n",
      "          [5.0241],\n",
      "          [5.0028]],\n",
      "\n",
      "         [[5.0093],\n",
      "          [4.9920],\n",
      "          [4.9871],\n",
      "          ...,\n",
      "          [4.9972],\n",
      "          [5.0162],\n",
      "          [4.9876]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5.0081],\n",
      "          [5.0075],\n",
      "          [5.0195],\n",
      "          ...,\n",
      "          [5.0136],\n",
      "          [5.0065],\n",
      "          [4.9922]],\n",
      "\n",
      "         [[5.0111],\n",
      "          [5.0078],\n",
      "          [5.0066],\n",
      "          ...,\n",
      "          [5.0152],\n",
      "          [5.0044],\n",
      "          [5.0020]],\n",
      "\n",
      "         [[5.0042],\n",
      "          [4.9982],\n",
      "          [4.9956],\n",
      "          ...,\n",
      "          [5.0012],\n",
      "          [5.0028],\n",
      "          [5.0028]]]], grad_fn=<UnsqueezeBackward0>)]\n",
      "tensor(2.1388, grad_fn=<AddBackward0>) tensor(0.4368, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with open('/ceph/raunaks/lsd-signet/reconstruction/config/debug.yaml', 'r') as f:\n",
    "    config = yaml.load(f)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"CUDA NOT available\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "geonet = GeoNetModel(config, False, device)\n",
    "geonet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
